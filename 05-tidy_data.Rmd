# Initial Data Tidying and exploration {#tidy_data}

## Introduction 

>'Can you do Addition?' the White Queen asked. 'What's one and one and one and one and one and one and one and one and one and one?'
>'I don't know,' said Alice. 'I lost count.'

[REF TO THROUGH THE LOOKING GLASS]


Computer's operate with linear streams of discrete values. People don't. One of the first challenges in data science is therefore understanding how computers process digital data, when they are reading the data, working with the data, and writing out the data. This chapter will provide this understanding, in order to make sure you use approaches for writing and reading data that are appropriate for the tasks. 



## Eight ways of dividing file and data types 

There are many types of files on computers, usually identified with different file extensions, such as `.zip`, `.csv`, `.exe`, `.doc`, `.pdf`, and so on. Such files can be categorised into two groups:

* Text files
* Binary files 

A text file is a file that, when opened with a basic text editor, like Notepad on Windows or TextEdit on OSX, will tend to display strings of characters that are human readable. A poem or short note written in Notepad would be an example of this, but so are other types of file that, though not written so as to be read by people (at least not for fun or enlightenment) nevertheless clearly contain text when displayed in a text editor. 

As an example of a text file written in a plain text format, we can look to Project Gutenberg [REF], an online repository of classic literature that's old enough to be copyright free. This is accessible within R through a package called `gutenbergr`[REF]. With a few lines of code we can download and jump right into some plain text data clearly meant for humans rather than machines: 

```{r looking_glass}
require(tidyverse)
require(gutenbergr)
gutenberg_metadata %>% 
  filter(title == "Through the Looking-Glass")

looking_glass <- gutenberg_download(12)

looking_glass[100:105,"text"]

```
By contrast, binary files are all other file types. The term 'binary' refers to the fact that computers work with zeros and ones. Binary files are those that don't clearly or obviously display as text when you look at them through a basic text editor. Instead the computer needs something more specialised to the type of data in order to make sense of it. 

The `readLines` function tries to load and display the contents of any file, assuming it is a text file, even when it is not. For example, if we try to read the first five 'lines' of an .mp3 file of a song by the Norwegian electronic music duo Royksopp, we get the following:


```{r read_rproj_as_lines}
readLines("chapter_support/05/03 49 Percent.mp3", n = 5)

```

(Note: the above text still does not make any sense even if you read Norwegian!)

A second way of distinguishing between types of files, more relevant when thinking about data files, is the following:

* Rectangular data files
* Non-rectangular data files 

To some extent, the difference between these two types of data should be obvious: a rectangular data file contains data that the computer expects to be arranged in some kind of rectangular table. Non-rectangular data is any other type of data. 

An example of rectangular data, available from the data-sharing website `figshare`, is shown below. The data reports the body mass index (BMIs) of participants in a study recorded at different time points. In the example below, the first five lines of the data are first loaded with the `readLines` function we used earlier, then using a special function, `read_csv` designed to work with rectangular data through an understanding of how the stream of data inside the file is split into different columns and rows:

```{r text_rectangle_example}
readLines("https://ndownloader.figshare.com/files/10905845", n = 5)
read_csv("https://ndownloader.figshare.com/files/10905845", n_max = 5)

```

We can see in the two examples above that, though the `readLines` function has split the above data into different rows, the contents within each row are stuck together, separated by the `,` symbol. The `read_csv` function, however, has split these values into separate columns, producing the rectangle of data that we largely expect. The `read_csv` output still has some problems, which we will fix later, but it's more suitable for this type of data. 


It's likely that you'll be working with rectangular data most of the time. However it's useful to be aware of what non-rectangular data can look like, and to think about the cases where non-rectangular data structures are most appropriate. Much of the internet is built using structured non-rectangular data written as text files. An simple example of this is the following:

```{r json_example}
require(jsonlite)

readLines("chapter_support/05/simple_json.json")

read_json("chapter_support/05/simple_json.json")

```

Non-rectangular data structures are hierarchical and tree-like. This ordered structure can be shown more clearly using the function `Hmisc::list.tree()` function, below:


```{r vis_json_tree}

json_dta <- read_json("chapter_support/05/simple_json.json")
#json_dta %>% data.tree::as.Node() %>% plot()
json_dta %>% Hmisc::list.tree()
```

In the above, the data structure has a single 'root', which splits into two branches, `edibles` and `inedibles`. The `edibles` branch itself has two branches, `fruit` and `vegetables`, which have four and three sub-branches respectively. At the end of the sub-branches are the data objects themselves themselves: four fruits, and three vegetables. The `inexibles` branch is less deep, and leads directly to four objects at the same level. 

> Activity: graphically draw the above tree. 


### Rectangular representation of the above

The same information can often be represented using either rectangular or non-rectangular data structures. For example, a rectangular representation of the above data is as follows: 

```{r rect_rep}
rect_rep <- 
  tribble(
    ~edi_class, ~fruit_or_veg, ~name,
    "edibles",   "fruit",       "apples",
    "edibles",   "fruit",       "oranges",
    "edibles",   "fruit",       "tomatoes",
    "edibles",   "fruit",       "lemons",
    "edibles",   "vegetables",  "potatoes",
    "edibles",   "vegetables",  "sweet potatoes",
    "edibles",   "vegetables",  "aubergines",
    "inedibles", NA,            "tables",
    "inedibles", NA,            "benches", 
    "inedibles", NA,            "chairs",
    "inedibles", NA,            "pots"
)

print(rect_rep, n=20)

```

Note in the above the use of quotation marks `\"` for the contents of the cells in the rectangles. This tells R that the expected content of the cell should be a character string, and that this character string will be created within the code itself, rather than fetched from somewhere else. 

Note also the use of `NA`. This means "not applicable", and tells R that the cells being referred to should be left 'empty' rather than filled with a value. In the above example, `NA` is used to indicate that it is not appropriate to try to categorise pots, benches, chairs and other inedibles as either a fruit or a vegetable. Often, `NA` is also used to indicate that data are missing, rather than that the fields (broadly synonymous with columns when working with rectangular data) are inappropriate.   

## Data and metadata 

Another useful distinction when considering the contents of a file is between 'data', i.e. the values on which various forms of quantitative analyses will be performed, and metadata, meaning additional information relating to the data. The distinction is not always hard-and-fast, as information that could be metadata in one file could be provided as data in another, but often important to bear in mind. 

As a simple example of the data/metadata distinction, let's return to the data downloaded from `figshare` earlier. A direct link to the data itself was used earlier, but to make sense of the data, additional information is needed, which is available from [this URL](https://figshare.com/articles/Northwestern_Medicine_BMI_data/6059513). When this website is looked at through a web browser, we can see both a preview of the contents of the data which we downloaded earlier, and below that some further information:

> *Northwestern Medicine BMI data*

>Dataset posted on 21.12.2017, 12:49 by John C. Lang Hans De Sterck Daniel M. Abrams

>Northwestern Medicine (NU) data are stored in NU.csv comma separated values (CSV) format. This file contains five columns: year t, BMI in year t, BMI in year t + 1, age in year t, and gender. Note: When BMI in year t + 1 is unavailable then the entry in the third column is -1.

We can think of the contents of the paragraph at the bottom as containing the 'metadata' we need to use the data appropriately. We know from this three new things:

1. The column names are not really the names of the names of the first row. 
2. One of the columns indicates a year, two indicate BMI values, one indicates age, and one indicates gender 
3. The value `-1` has a special meaning. It means the data are missing for that participant in that year. 

With the above metadata, we can reload and re-format the data in a more appropriate way. 

We can start by giving appropriate names to each column. This means that the values of the first row in the dataset are not used (incorrectly) as the column names. 

```{r reload_bmi_data, cache = T}
bmi_dta <-
  read_csv(file = "https://ndownloader.figshare.com/files/10905845", 
         col_names = c("year", "bmi_t0", "bmi_t1", "age_t0", "gender")
         )

```

Next we can change the `-1` values to `NA`, R's way of representing missing data. 

```{r}
bmi_dta <- 
  bmi_dta %>% 
  mutate_each(funs(ifelse(. == -1, NA, .)))

bmi_dta

```

Notice that the second column, which used to be `-1`, is now listed correctly as `NA`, i.e. missing. 

In the above example we used the term `metadata` to refer to information that we inferred by reading some text meant for people to read. Often `metadata` is used in a more formal way, to refer to data about data written for machines to understand. 

For example, the gender column currently contains `1`s and `0`s. We know that it refers to two distinct categories of participant, male and female, but R does not. R would have to be told explicitly about the categorical quality of the values in this column, as otherwise it may process the data in inappropriate ways. For instance, if we try to summarise the contents of this column, we are likely to be interested in the numbers of males and females in the dataset. However, R might expect us to be interested in the average value of all rows in the column.


```{r}
summary(bmi_dta)

```

In the above, the summary for the gender colunn gives a mean of `0.3692`, indicating that around 37% of the participants are of the gender indicated by the value `1`. However, a more appropriate way of summarising this column might be to give a tally of each category of participants. 

We can get a sense of the kind of meta-data R has attached to each column by looking back at the table output when we printed `bmi_dta` above. Immediately below the column names is a line containing either `<int>` or `<dbl>`. `<int>` means 'integer', and means that only whole numbers (`0`, `1`, `2`, `3`, etc.) are accepted in that column, and `<dbl>` means 'double', which means that non-integer numeric values, like `2.15`, are also acceptable as inputs. 

We can change the metadata associated with the `gender` column to indicate a different data type, suitable for this type of information, in the following way

```{r}
bmi_dta %>% 
  mutate(gender = factor(gender))
```

The column `gender` now has the data type indicator `<fctr>` just beneath it, suggesting it is now a factor. We can now see how the `summary()` function works differently with this data type than the earlier, integer data type.


```{r}
bmi_dta %>% 
  mutate(gender = factor(gender)) %>% 
  summary()

```

The `summary()` function now summarises the gender column in a different way, with a tabulation by group rather than mean of the values. 

One point we should note in the above is that we still do not know, from the information provided, which label (0 or 1) refers to which gender. Does a `1` indicate males, or females? Frustratingly, this information is not clearly stated in the associated article or appendices either (ref: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0189795). 
Because of this, we may have to look at the associated code in order to guage this basic fact with certainty, though we can probably guess which code refers to which gender using some additional domain knowledge:

* Females live longer than males, so *if the hospital sample data are representative* of the whole US population, we might expect a higher average age for females than males. We might also expect the upper end of the distribution, such as the upper quantile (the age at which 25% of the sample are older and 75% are younger) to be higher too.
* Females tend to have somewhat higher variance in BMIs than males. 

Let's try to infer gender using this additional information, by summarising some key statistics for various columns by gender.

```{r}
bmi_dta %>% 
  group_by(gender) %>% 
  summarise(
    mean_bmi = mean(bmi_t0, na.rm = T),
    var_bmi  = mean(bmi_t0, na.rm = T),
    mean_age = mean(age_t0, na.rm = T),
    uq_age   = quantile(age_t0, probs = 0.75, na.rm = T)
  )
  
```

Based on this, we might feel more confident assuming that a `1` in the gender column indicates females, and so a `0` indicates males. Depending on how sure we need to be about this, we might either decide to go with these coding assumptions, or to seek further information to (dis)confirm this suspicion. 

For now, let's recode the gender according to our current best assumptions: 

```{r}
bmi_dta <- 
  bmi_dta %>% 
    mutate(gender = case_when(
      gender == 0 ~ 'male', 
      gender == 1 ~ 'female'
      ) %>% factor()
    ) 

bmi_dta

summary(bmi_dta)

```

The `gender` column now contains data of class `factor` (`<fctr>` in the above). We can see from the summary that the male number of rows per category is as before. 

Factors in R contain an additional type of metadata. Rather than repeatedly writing the word 'male' and 'female' in each row, R represents each label by a number, and contains a look-up table linking each number to each label. We can start to learn more about how R does this by typing the following:

```{r}
head(bmi_dta$gender)
head(as.numeric(bmi_dta$gender))
levels(bmi_dta$gender)

```

The first of these commands shows the first five items in the column: two males then three females. The second shows the numeric values actually stored, and the last function shows the labels associated with each successive numeric value in the look-up table. 
...


## Tidy and untidy data 

A final way of distinguishing between types of data 

Part (a) will introduce the primary distinction used by computer programmers between types of files, between human-readable text files and human-unreadable binary files. Examples of these two different types of files will be introduced, which also highlight another important conceptual distinction: the difference between data and meta-data (data about data). The relative advantages of different file types will be discussed, and the argument will be made that, as a rule-of-thumb, text files should be used in preference to binary files.

## Loading and saving data - R packages and functions

Part (b) will discuss some of the particular R packages and functions within that can be used to work with different file types, presenting even the loading of data as at iterative process of learning more about how variables in data are structured and saved, and how the information in these variables be best represented and operated with inside R. 

## Data tidying - principles and challenges 

Part (c) will introduce a further, higher level, distinction between types of data: from ‘untidy’ and ‘initial’ data to ‘tidy’ and ‘derived’ data. This section will frame much of the practical challenge of data science as involving first identifying what needs to be done to move from the former to the latter, and then knowing how to do this.

## Data tidying - tidyr and dplyr

Part (d) will introduce two closely linked R packages, tidyr and dplyr, as providing the tools necessary to complete the vast majority of data tidying and data derivation tasks.

## Initial Exploratory data analysis

Finally, part (e) will emphasise the importance of rapid exploratory data analysis both at the data tidying stage, and for developing familiarity and engagement with tidied data sources.
